{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#Face Recognition with Facebook DeepFace Model\n",
    "#Author Sefik Ilkin Serengil (sefiks.com)\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_size = (152, 152)\n",
    "\n",
    "#OpenCV haarcascade module\n",
    "\n",
    "opencv_home = cv2.__file__\n",
    "folders = opencv_home.split(os.path.sep)[0:-1]\n",
    "path = folders[0]\n",
    "for folder in folders[1:]:\n",
    "\tpath = path + \"/\" + folder\n",
    "\n",
    "detector_path = path+\"/data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "if os.path.isfile(detector_path) != True:\n",
    "\traise ValueError(\"Confirm that opencv is installed on your environment! Expected path \",detector_path,\" violated.\")\n",
    "else:\n",
    "\tface_cascade = cv2.CascadeClassifier(detector_path)\n",
    "\n",
    "#-------------------------\n",
    "def detectFace(img_path, target_size=(152, 152)):\n",
    "\t\n",
    "\timg = cv2.imread(img_path)\n",
    "\t\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tif len(faces) > 0:\n",
    "\t\tx,y,w,h = faces[0]\n",
    "\t\t\n",
    "\t\tmargin = 0\n",
    "\t\tx_margin = w * margin / 100\n",
    "\t\ty_margin = h * margin / 100\n",
    "\t\t\n",
    "\t\tif y - y_margin > 0 and y+h+y_margin < img.shape[1] and x-x_margin > 0 and x+w+x_margin < img.shape[0]:\n",
    "\t\t\tdetected_face = img[int(y-y_margin):int(y+h+y_margin), int(x-x_margin):int(x+w+x_margin)]\n",
    "\t\telse:\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "\t\t\n",
    "\t\tdetected_face = cv2.resize(detected_face, target_size)\n",
    "\t\t\n",
    "\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\n",
    "\t\t#normalize in [0, 1]\n",
    "\t\timg_pixels /= 255 \n",
    "\t\t\n",
    "\t\treturn img_pixels\n",
    "\telse:\n",
    "\t\traise ValueError(\"Face could not be detected in \", img_path,\". Please confirm that the picture is a face photo.\")\n",
    "\n",
    "#-------------------------\n",
    "\n",
    "#DeepFace model\n",
    "base_model = Sequential()\n",
    "base_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n",
    "base_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n",
    "base_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n",
    "base_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n",
    "base_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n",
    "base_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n",
    "base_model.add(Flatten(name='F0'))\n",
    "base_model.add(Dense(4096, activation='relu', name='F7'))\n",
    "base_model.add(Dropout(rate=0.5, name='D0'))\n",
    "base_model.add(Dense(8631, activation='softmax', name='F8'))\n",
    "\n",
    "base_model.load_weights(\"E:/25. Face Recognition/weight/VGGFace2_DeepFace_weights_val-0.9034.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Drop F8 and D0 layers. F7 is the representation layer.\n",
    "model = Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n",
    "\n",
    "#------------------------\n",
    "def l2_normalize(x):\n",
    "\treturn x / np.sqrt(np.sum(np.multiply(x, x)))\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "\teuclidean_distance = source_representation - test_representation\n",
    "\teuclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "\teuclidean_distance = np.sqrt(euclidean_distance)\n",
    "\treturn euclidean_distance\n",
    "\n",
    "#------------------------\t\n",
    "\n",
    "#put your employee pictures in this path as name_of_employee.jpg\n",
    "employee_pictures = \"database/\"\n",
    "\n",
    "employees = dict()\n",
    "\n",
    "for file in listdir(employee_pictures):\n",
    "\temployee, extension = file.split(\".\")\n",
    "\timg_path = 'database/%s.jpg' % (employee)\n",
    "\timg = detectFace(img_path)\n",
    "\t\n",
    "\trepresentation = model.predict(img)[0]\n",
    "\t\n",
    "\temployees[employee] = representation\n",
    "\t\n",
    "print(\"employee representations retrieved successfully\")\n",
    "\n",
    "#------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected:  Siyam ( 0.6873781 )\n",
      "detected:  Siyam ( 0.6955341 )\n",
      "detected:  Siyam ( 0.6715271 )\n",
      "detected:  Siyam ( 0.67698294 )\n",
      "detected:  Siyam ( 0.69483995 )\n",
      "detected:  Siyam ( 0.679735 )\n",
      "detected:  Siyam ( 0.6846454 )\n",
      "detected:  Siyam ( 0.68218833 )\n",
      "detected:  Siyam ( 0.67936236 )\n",
      "detected:  Siyam ( 0.67503446 )\n",
      "detected:  Siyam ( 0.68118954 )\n",
      "detected:  Siyam ( 0.6890777 )\n",
      "detected:  Siyam ( 0.6917525 )\n",
      "detected:  Siyam ( 0.63866043 )\n",
      "detected:  Siyam ( 0.6442112 )\n",
      "detected:  Siyam ( 0.6330037 )\n",
      "detected:  Siyam ( 0.6444084 )\n",
      "detected:  Siyam ( 0.6082901 )\n",
      "detected:  Siyam ( 0.63129646 )\n",
      "detected:  Siyam ( 0.6603995 )\n",
      "detected:  Siyam ( 0.6265479 )\n",
      "detected:  Siyam ( 0.6557886 )\n",
      "detected:  Siyam ( 0.6548753 )\n",
      "detected:  Siyam ( 0.68370134 )\n",
      "detected:  Siyam ( 0.66743517 )\n",
      "detected:  Siyam ( 0.63926035 )\n",
      "detected:  Siyam ( 0.6559961 )\n",
      "detected:  Siyam ( 0.67306757 )\n",
      "detected:  Siyam ( 0.62500507 )\n",
      "detected:  Siyam ( 0.6619591 )\n",
      "detected:  Siyam ( 0.6964017 )\n",
      "detected:  Siyam ( 0.657245 )\n",
      "detected:  Siyam ( 0.6697495 )\n",
      "detected:  Siyam ( 0.61210346 )\n",
      "detected:  Siyam ( 0.67054486 )\n",
      "detected:  Siyam ( 0.6348767 )\n",
      "detected:  Siyam ( 0.6371938 )\n",
      "detected:  Siyam ( 0.6380265 )\n",
      "detected:  Siyam ( 0.62422365 )\n",
      "detected:  Siyam ( 0.6512456 )\n",
      "detected:  Siyam ( 0.6603605 )\n",
      "detected:  Siyam ( 0.65112 )\n",
      "detected:  Siyam ( 0.65525067 )\n",
      "detected:  Siyam ( 0.63919145 )\n",
      "detected:  Siyam ( 0.668517 )\n",
      "detected:  Siyam ( 0.6697977 )\n",
      "detected:  Siyam ( 0.6507608 )\n",
      "detected:  Siyam ( 0.6929226 )\n",
      "detected:  Siyam ( 0.6612204 )\n",
      "detected:  Siyam ( 0.6918539 )\n",
      "detected:  Siyam ( 0.6977727 )\n",
      "detected:  Siyam ( 0.6418828 )\n",
      "detected:  Siyam ( 0.63193035 )\n",
      "detected:  Siyam ( 0.6730802 )\n",
      "detected:  Siyam ( 0.6819373 )\n",
      "detected:  Siyam ( 0.62600505 )\n",
      "detected:  Siyam ( 0.64864326 )\n",
      "detected:  Siyam ( 0.6403948 )\n",
      "detected:  Siyam ( 0.6476632 )\n",
      "detected:  Siyam ( 0.6343224 )\n",
      "detected:  Siyam ( 0.6327007 )\n",
      "detected:  Siyam ( 0.64342767 )\n",
      "detected:  Siyam ( 0.62075853 )\n",
      "detected:  Siyam ( 0.66942024 )\n",
      "detected:  Siyam ( 0.66329104 )\n",
      "detected:  Siyam ( 0.63674504 )\n",
      "detected:  Siyam ( 0.65702844 )\n",
      "detected:  Siyam ( 0.67047405 )\n",
      "detected:  Siyam ( 0.65333986 )\n",
      "detected:  Siyam ( 0.6825836 )\n",
      "detected:  Siyam ( 0.6296951 )\n",
      "detected:  Siyam ( 0.64925236 )\n",
      "detected:  Siyam ( 0.6649611 )\n",
      "detected:  Siyam ( 0.62599903 )\n",
      "detected:  Siyam ( 0.6650747 )\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam\n",
    "\n",
    "while(True):\n",
    "\tret, img = cap.read()\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #discard small detected faces\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\tdetected_face = cv2.resize(detected_face, target_size) #resize to 152x152\n",
    "\t\t\t\n",
    "\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\timg_pixels /= 255\n",
    "\t\t\t\n",
    "\t\t\tcaptured_representation = model.predict(img_pixels)[0]\n",
    "\t\t\t\n",
    "\t\t\tdistances = []\n",
    "\t\t\t\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tsource_representation = employees[i]\n",
    "\t\t\t\t\n",
    "\t\t\t\tdistance = findEuclideanDistance(l2_normalize(captured_representation), l2_normalize(source_representation))\n",
    "\t\t\t\tdistances.append(distance)\n",
    "\t\t\t\n",
    "\t\t\tis_found = False; index = 0\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tif index == np.argmin(distances):\n",
    "\t\t\t\t\tif distances[index] <= 0.70:\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tprint(\"detected: \",employee_name, \"(\",distances[index],\")\")\n",
    "\t\t\t\t\t\temployee_name = employee_name.replace(\"_\", \"\")\n",
    "\t\t\t\t\t\tsimilarity = distances[index]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tis_found = True\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\t\t\n",
    "\t\t\tif is_found:\n",
    "\t\t\t\tdisplay_img = cv2.imread(\"database/%s.jpg\" % employee_name)\n",
    "\t\t\t\tpivot_img_size = 112\n",
    "\t\t\t\tdisplay_img = cv2.resize(display_img, (pivot_img_size, pivot_img_size))\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tresolution_x = img.shape[1]; resolution_y = img.shape[0]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tlabel = employee_name+\" (\"+\"{0:.2f}\".format(similarity)+\")\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n",
    "\t\t\t\t\t\t#top right\n",
    "\t\t\t\t\t\timg[y - pivot_img_size:y, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y), (x+3*int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+3*int(w/4), y-int(pivot_img_size/2)), (x+w, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\telif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#bottom left\n",
    "\t\t\t\t\t\timg[y+h:y+h+pivot_img_size, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y+h), (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)), (x, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#top left\n",
    "\t\t\t\t\t\timg[y-pivot_img_size:y, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y), (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)), (x, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif x+w+pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n",
    "\t\t\t\t\t\t#bottom righ\n",
    "\t\t\t\t\t\timg[y+h:y+h+pivot_img_size, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y+h), (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)), (x+w, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(\"exception occured: \", str(e))\n",
    "\t\t\t\n",
    "\tcv2.imshow('img',img)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "\t\tbreak\n",
    "\t\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
