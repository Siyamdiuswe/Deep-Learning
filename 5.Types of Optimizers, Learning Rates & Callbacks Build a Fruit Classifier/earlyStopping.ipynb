{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"earlyStopping.ipynb","provenance":[],"mount_file_id":"1QQdx64eGA4A6-CTDPkCH2mx1CDnm3oTm","authorship_tag":"ABX9TyMJIOS7y6/Czldv9jqzGudh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0FGLcEoom6Xn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":899},"outputId":"c6a36021-de6b-4b73-83e5-45fd90198351","executionInfo":{"status":"ok","timestamp":1584304451120,"user_tz":-360,"elapsed":2825,"user":{"displayName":"Sohaib Ahammed Siuam","photoUrl":"","userId":"01220721241874729640"}}},"source":["from keras.datasets import mnist\n","from keras.utils import np_utils\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","import os\n","\n","# Training Parameters\n","batch_size = 64\n","epochs = 15\n","\n","# loads the MNIST dataset\n","(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n","\n","# Lets store the number of rows and columns\n","img_rows = x_train[0].shape[0]\n","img_cols = x_train[1].shape[0]\n","\n","# Getting our date in the right 'shape' needed for Keras\n","# We need to add a 4th dimenion to our date thereby changing our\n","# Our original image shape of (60000,28,28) to (60000,28,28,1)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","\n","# store the shape of a single image \n","input_shape = (img_rows, img_cols, 1)\n","\n","# change our image type to float32 data type\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n","x_train /= 255\n","x_test /= 255\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Now we one hot encode outputs\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)\n","\n","# Let's count the number columns in our hot encoded matrix \n","print (\"Number of Classes: \" + str(y_test.shape[1]))\n","\n","num_classes = y_test.shape[1]\n","num_pixels = x_train.shape[1] * x_train.shape[2]\n","\n","# create model\n","model = Sequential()\n","\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = keras.optimizers.Adadelta(),\n","              metrics = ['accuracy'])\n","\n","print(model.summary())\n","\n","                     \n","checkpoint = ModelCheckpoint(\"/content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\",\n","                             monitor=\"val_loss\",\n","                             mode=\"min\",\n","                             save_best_only = True,\n","                             verbose=1)\n","callbacks = [checkpoint]\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n","Number of Classes: 10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               1179776   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 1,199,882\n","Trainable params: 1,199,882\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yOURThyk4_7A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6282182b-2ff7-4702-92cf-a523ad0cc36c","executionInfo":{"status":"ok","timestamp":1584304666450,"user_tz":-360,"elapsed":209971,"user":{"displayName":"Sohaib Ahammed Siuam","photoUrl":"","userId":"01220721241874729640"}}},"source":["history = model.fit(x_train, y_train,\n","          batch_size = batch_size,\n","          epochs = epochs,\n","          verbose = 1,\n","          callbacks = callbacks,\n","          validation_data = (x_test, y_test))\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/15\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","60000/60000 [==============================] - 16s 263us/step - loss: 0.2198 - acc: 0.9329 - val_loss: 0.0501 - val_acc: 0.9836\n","\n","Epoch 00001: val_loss improved from inf to 0.05013, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 2/15\n","60000/60000 [==============================] - 13s 219us/step - loss: 0.0839 - acc: 0.9750 - val_loss: 0.0424 - val_acc: 0.9860\n","\n","Epoch 00002: val_loss improved from 0.05013 to 0.04237, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 3/15\n","60000/60000 [==============================] - 13s 219us/step - loss: 0.0608 - acc: 0.9824 - val_loss: 0.0408 - val_acc: 0.9866\n","\n","Epoch 00003: val_loss improved from 0.04237 to 0.04077, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 4/15\n","60000/60000 [==============================] - 13s 218us/step - loss: 0.0525 - acc: 0.9845 - val_loss: 0.0330 - val_acc: 0.9886\n","\n","Epoch 00004: val_loss improved from 0.04077 to 0.03305, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 5/15\n","60000/60000 [==============================] - 13s 219us/step - loss: 0.0457 - acc: 0.9865 - val_loss: 0.0349 - val_acc: 0.9891\n","\n","Epoch 00005: val_loss did not improve from 0.03305\n","Epoch 6/15\n","60000/60000 [==============================] - 13s 218us/step - loss: 0.0410 - acc: 0.9876 - val_loss: 0.0329 - val_acc: 0.9903\n","\n","Epoch 00006: val_loss improved from 0.03305 to 0.03293, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 7/15\n","60000/60000 [==============================] - 13s 220us/step - loss: 0.0397 - acc: 0.9880 - val_loss: 0.0312 - val_acc: 0.9899\n","\n","Epoch 00007: val_loss improved from 0.03293 to 0.03120, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 8/15\n","60000/60000 [==============================] - 13s 218us/step - loss: 0.0370 - acc: 0.9885 - val_loss: 0.0300 - val_acc: 0.9903\n","\n","Epoch 00008: val_loss improved from 0.03120 to 0.02999, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 9/15\n","60000/60000 [==============================] - 13s 221us/step - loss: 0.0344 - acc: 0.9890 - val_loss: 0.0262 - val_acc: 0.9914\n","\n","Epoch 00009: val_loss improved from 0.02999 to 0.02615, saving model to /content/drive/My Drive/DeepLearningCV/12. Optimizers, Adaptive Learning Rate & Callbacks/MNIST_Checkpoint.h5\n","Epoch 10/15\n","60000/60000 [==============================] - 13s 222us/step - loss: 0.0366 - acc: 0.9889 - val_loss: 0.0273 - val_acc: 0.9911\n","\n","Epoch 00010: val_loss did not improve from 0.02615\n","Epoch 11/15\n","60000/60000 [==============================] - 13s 219us/step - loss: 0.0334 - acc: 0.9897 - val_loss: 0.0291 - val_acc: 0.9907\n","\n","Epoch 00011: val_loss did not improve from 0.02615\n","Epoch 12/15\n","60000/60000 [==============================] - 13s 219us/step - loss: 0.0332 - acc: 0.9903 - val_loss: 0.0310 - val_acc: 0.9908\n","\n","Epoch 00012: val_loss did not improve from 0.02615\n","Epoch 13/15\n","60000/60000 [==============================] - 13s 219us/step - loss: 0.0311 - acc: 0.9907 - val_loss: 0.0293 - val_acc: 0.9915\n","\n","Epoch 00013: val_loss did not improve from 0.02615\n","Epoch 14/15\n","60000/60000 [==============================] - 13s 218us/step - loss: 0.0307 - acc: 0.9907 - val_loss: 0.0296 - val_acc: 0.9917\n","\n","Epoch 00014: val_loss did not improve from 0.02615\n","Epoch 15/15\n","60000/60000 [==============================] - 13s 218us/step - loss: 0.0296 - acc: 0.9908 - val_loss: 0.0280 - val_acc: 0.9928\n","\n","Epoch 00015: val_loss did not improve from 0.02615\n","Test loss: 0.02798222940974897\n","Test accuracy: 0.9928\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mvZiHCpd5FSv","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', # value being monitored for improvement\n","                          min_delta = 0, #Abs value and is the min change required before we stop\n","                          patience = 3, #Number of epochs we wait before stopping \n","                          verbose = 1,\n","                          restore_best_weights = True) #keeps the best weigths once stopped\n","\n","# we put our call backs into a callback list\n","callbacks = [earlystop, checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iieikE7H6PYK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":394},"outputId":"32fc3978-d5f5-44e2-f36f-1ea15154a369","executionInfo":{"status":"ok","timestamp":1584304751676,"user_tz":-360,"elapsed":55205,"user":{"displayName":"Sohaib Ahammed Siuam","photoUrl":"","userId":"01220721241874729640"}}},"source":["history = model.fit(x_train, y_train,\n","          batch_size=64,\n","          epochs=50,\n","          verbose=1,\n","          callbacks = callbacks,\n","          validation_data=(x_test, y_test))\n","\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 14s 225us/step - loss: 0.0269 - acc: 0.9920 - val_loss: 0.0269 - val_acc: 0.9920\n","\n","Epoch 00001: val_loss did not improve from 0.02615\n","Epoch 2/50\n","60000/60000 [==============================] - 13s 222us/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.0299 - val_acc: 0.9909\n","\n","Epoch 00002: val_loss did not improve from 0.02615\n","Epoch 3/50\n","60000/60000 [==============================] - 13s 221us/step - loss: 0.0263 - acc: 0.9920 - val_loss: 0.0291 - val_acc: 0.9912\n","\n","Epoch 00003: val_loss did not improve from 0.02615\n","Epoch 4/50\n","60000/60000 [==============================] - 13s 221us/step - loss: 0.0267 - acc: 0.9925 - val_loss: 0.0325 - val_acc: 0.9908\n","Restoring model weights from the end of the best epoch\n","\n","Epoch 00004: val_loss did not improve from 0.02615\n","Epoch 00004: early stopping\n","Test loss: 0.026911518605536002\n","Test accuracy: 0.992\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nxztF9PZ6aLd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}